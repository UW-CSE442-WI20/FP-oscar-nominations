{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Cleaning \"title_basics.tsv\" into \"movie_titles\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pathlib as path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_path = path.Path().absolute()\n",
    "#Importing the dataframe by every 1 million tuples because the full dataset is too large for one dataframe\n",
    "try:\n",
    "    n_1 = pd.read_csv(str(rel_path) + r\"\\raw_data\\title_basics.tsv\", sep='\\t', nrows = 1000000)\n",
    "    n_2 = pd.read_csv(str(rel_path) + r\"\\raw_data\\title_basics.tsv\", sep='\\t',skiprows= range(1, 1000000), nrows = 1000000)\n",
    "    n_3 = pd.read_csv(str(rel_path) + r\"\\raw_data\\title_basics.tsv\", sep='\\t',skiprows= range(1, 2000000), nrows = 1000000)\n",
    "    n_4 = pd.read_csv(str(rel_path) + r\"\\raw_data\\title_basics.tsv\", sep='\\t',skiprows= range(1, 3000000), nrows = 1000000)\n",
    "    n_5 = pd.read_csv(str(rel_path) + r\"\\raw_data\\title_basics.tsv\", sep='\\t',skiprows= range(1, 4000000), nrows = 1000000)\n",
    "    n_6 = pd.read_csv(str(rel_path) + r\"\\raw_data\\title_basics.tsv\", sep='\\t',skiprows= range(1, 5000000), nrows = 1000000)\n",
    "    n_7 = pd.read_csv(str(rel_path) + r\"\\raw_data\\title_basics.tsv\", sep='\\t',skiprows= range(1, 6000000), nrows = 1000000)\n",
    "    original_tuples = len(n_1) + len(n_2) + len(n_3) + len(n_4) + len(n_5) + len(n_6) + len(n_7)\n",
    "    original_size = n_1.size + n_2.size + n_3.size + n_4.size + n_5.size + n_6.size + n_7.size\n",
    "except:\n",
    "    print(\"You're massing the title_basics.tsv file. Download it from the following link and unzip it to the raw_data folder. Then restart the kernel and rerun\")\n",
    "    print(\"https://datasets.imdbws.com/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing all non-movie titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_1 = n_1[(n_1['titleType']== 'movie') | (n_1['titleType']== 'short')]\n",
    "n_2 = n_2[(n_2['titleType']== 'movie') | (n_2['titleType']== 'short')]\n",
    "n_3 = n_3[(n_3['titleType']== 'movie') | (n_3['titleType']== 'short')]\n",
    "n_4 = n_4[(n_4['titleType']== 'movie') | (n_4['titleType']== 'short')]\n",
    "n_5 = n_5[(n_5['titleType']== 'movie') | (n_5['titleType']== 'short')]\n",
    "n_6 = n_6[(n_6['titleType']== 'movie') | (n_6['titleType']== 'short')]\n",
    "n_7 = n_7[(n_7['titleType']== 'movie') | (n_7['titleType']== 'short')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remerging original dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_titles = pd.concat([\n",
    "    n_1,\n",
    "    n_2,\n",
    "    n_3,\n",
    "    n_4,\n",
    "    n_5,\n",
    "    n_6,\n",
    "    n_7\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing Adult Titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_titles = movie_titles[movie_titles['isAdult'] == 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping extraneous columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "del movie_titles['endYear']\n",
    "del movie_titles['isAdult']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replacing \\N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_titles = movie_titles.copy()\n",
    "movie_titles['startYear'] = pd.to_numeric(movie_titles['startYear'], errors = 'coerce')\n",
    "movie_titles['runtimeMinutes'] = pd.to_numeric(movie_titles['runtimeMinutes'], errors = 'coerce')\n",
    "movie_titles = movie_titles.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing years before 1929"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_titles = movie_titles[movie_titles['startYear'] >= 1929]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exporting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_titles.to_csv(str(rel_path) + r'\\..\\src\\titles_during_oscars.csv')\n",
    "new_tuples = len(movie_titles)\n",
    "new_size = movie_titles.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Tuple Count:\t6561312\n",
      "Cleansed Tuple Count:\t1045419\n",
      "Tuples Reduced By: \t84.07%\n",
      "Size Reduced By: \t87.61%\n"
     ]
    }
   ],
   "source": [
    "print(\"Original Tuple Count:\\t\"+str(original_tuples))\n",
    "print(\"Cleansed Tuple Count:\\t\"+ str(new_tuples))\n",
    "percent_tuple_reduction = (100 - round((100 * new_tuples) / original_tuples, 2))\n",
    "print(\"Tuples Reduced By: \\t\"+ str(percent_tuple_reduction)+ \"%\")\n",
    "percent_size_reduction = (100 - round((100 * new_size) / original_size, 2))\n",
    "print('Size Reduced By: \\t' + str(percent_size_reduction) + \"%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
