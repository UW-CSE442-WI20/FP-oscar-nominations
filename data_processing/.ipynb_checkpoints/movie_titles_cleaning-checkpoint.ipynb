{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Cleaning \"title_basics.tsv\" into \"movie_titles\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib\n",
    "import numpy\n",
    "import pathlib as path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wolf1\\AppData\\Roaming\\Python\\Python37\\site-packages\\IPython\\core\\interactiveshell.py:3044: DtypeWarning: Columns (5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "rel_path = path.Path().absolute()\n",
    "#Importing the dataframe by every 1 million tuples because the full dataset is too large for one dataframe\n",
    "try:\n",
    "    first_ten_thou = pd.read_csv(str(rel_path) + r\"\\raw_data\\title_basics.tsv\", sep='\\t', nrows = 1000000)\n",
    "    sec_ten_thou = pd.read_csv(str(rel_path) + r\"\\raw_data\\title_basics.tsv\", sep='\\t',skiprows= range(1, 1000000), nrows = 1000000)\n",
    "    thir_ten_thou = pd.read_csv(str(rel_path) + r\"\\raw_data\\title_basics.tsv\", sep='\\t',skiprows= range(1, 2000000), nrows = 1000000)\n",
    "    four_ten_thou = pd.read_csv(str(rel_path) + r\"\\raw_data\\title_basics.tsv\", sep='\\t',skiprows= range(1, 3000000), nrows = 1000000)\n",
    "    five_ten_thou = pd.read_csv(str(rel_path) + r\"\\raw_data\\title_basics.tsv\", sep='\\t',skiprows= range(1, 4000000), nrows = 1000000)\n",
    "    six_ten_thou = pd.read_csv(str(rel_path) + r\"\\raw_data\\title_basics.tsv\", sep='\\t',skiprows= range(1, 5000000), nrows = 1000000)\n",
    "    fin_ten_thou = pd.read_csv(str(rel_path) + r\"\\raw_data\\title_basics.tsv\", sep='\\t',skiprows= range(1, 6000000), nrows = 1000000)\n",
    "    original_tuples = len(first_ten_thou) + len(sec_ten_thou) + len(thir_ten_thou) + len(four_ten_thou) + len(five_ten_thou) + len(six_ten_thou) + len(fin_ten_thou)\n",
    "    original_size = first_ten_thou.size + sec_ten_thou.size + thir_ten_thou.size + four_ten_thou.size + five_ten_thou.size + six_ten_thou.size + fin_ten_thou.size\n",
    "except:\n",
    "    print(\"You're massing the title_basics.tsv file. Download it from the following link and unzip it to the raw_data folder. Then restart the kernel and rerun\")\n",
    "    print(\"https://datasets.imdbws.com/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing all non-movie titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_ten_thou = first_ten_thou[(first_ten_thou['titleType']== 'movie')]\n",
    "sec_ten_thou = sec_ten_thou[(sec_ten_thou['titleType']== 'movie')]\n",
    "thir_ten_thou = thir_ten_thou[(thir_ten_thou['titleType']== 'movie')]\n",
    "four_ten_thou = four_ten_thou[(four_ten_thou['titleType']== 'movie')]\n",
    "five_ten_thou = five_ten_thou[(five_ten_thou['titleType']== 'movie')]\n",
    "six_ten_thou = six_ten_thou[(six_ten_thou['titleType']== 'movie')]\n",
    "fin_ten_thou = fin_ten_thou[(fin_ten_thou['titleType']== 'movie')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remerging original dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_titles = pd.concat([\n",
    "    first_ten_thou,\n",
    "    sec_ten_thou,\n",
    "    thir_ten_thou,\n",
    "    four_ten_thou,\n",
    "    five_ten_thou,\n",
    "    six_ten_thou,\n",
    "    fin_ten_thou\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping extraneous columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "del movie_titles['endYear']\n",
    "del movie_titles['titleType']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replacing \\N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_titles = movie_titles.copy()\n",
    "movie_titles['startYear'] = pd.to_numeric(movie_titles['startYear'], errors = 'coerce')\n",
    "movie_titles['runtimeMinutes'] = pd.to_numeric(movie_titles['runtimeMinutes'], errors = 'coerce')\n",
    "movie_titles = movie_titles.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exporting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_titles.to_csv(str(rel_path) + r'\\..\\src\\movie_titles.csv')\n",
    "new_tuples = len(movie_titles)\n",
    "new_size = movie_titles.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Tuple Count:\t6561312\n",
      "Cleansed Tuple Count:\t544052\n",
      "Tuples Reduced By: \t91.71000000000001%\n",
      "Size Reduced By: \t93.55%\n",
      "Size Reduction: \t94.56%\n"
     ]
    }
   ],
   "source": [
    "print(\"Original Tuple Count:\\t\"+str(original_tuples))\n",
    "print(\"Cleansed Tuple Count:\\t\"+ str(new_tuples))\n",
    "percent_tuple_reduction = (100 - round((100 * new_tuples) / original_tuples, 2))\n",
    "print(\"Tuples Reduced By: \\t\"+ str(percent_tuple_reduction)+ \"%\")\n",
    "percent_size_reduction = (100 - round((100 * new_size) / original_size, 2))\n",
    "print('Size Reduced By: \\t' + str(percent_size_reduction) + \"%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
