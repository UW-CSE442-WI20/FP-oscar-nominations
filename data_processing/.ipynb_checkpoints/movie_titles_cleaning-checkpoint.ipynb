{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Cleaning \"title_basics.tsv\" into \"movie_titles\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib\n",
    "import numpy\n",
    "import pathlib as path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wolf1\\AppData\\Roaming\\Python\\Python37\\site-packages\\IPython\\core\\interactiveshell.py:3044: DtypeWarning: Columns (5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "rel_path = path.Path().absolute()\n",
    "#Importing the dataframe by every 1 million tuples because the full dataset is too large for one dataframe\n",
    "first_ten_thou = pd.read_csv(str(rel_path) + r\"\\raw_data\\title_basics.tsv\", sep='\\t', nrows = 1000000)\n",
    "sec_ten_thou = pd.read_csv(str(rel_path) + r\"\\raw_data\\title_basics.tsv\", sep='\\t',skiprows= range(1, 1000000), nrows = 1000000)\n",
    "thir_ten_thou = pd.read_csv(str(rel_path) + r\"\\raw_data\\title_basics.tsv\", sep='\\t',skiprows= range(1, 2000000), nrows = 1000000)\n",
    "four_ten_thou = pd.read_csv(str(rel_path) + r\"\\raw_data\\title_basics.tsv\", sep='\\t',skiprows= range(1, 3000000), nrows = 1000000)\n",
    "five_ten_thou = pd.read_csv(str(rel_path) + r\"\\raw_data\\title_basics.tsv\", sep='\\t',skiprows= range(1, 4000000), nrows = 1000000)\n",
    "six_ten_thou = pd.read_csv(str(rel_path) + r\"\\raw_data\\title_basics.tsv\", sep='\\t',skiprows= range(1, 5000000), nrows = 1000000)\n",
    "fin_ten_thou = pd.read_csv(str(rel_path) + r\"\\raw_data\\title_basics.tsv\", sep='\\t',skiprows= range(1, 6000000), nrows = 1000000)\n",
    "original_tuples = len(first_ten_thou) + len(sec_ten_thou) + len(thir_ten_thou) + len(four_ten_thou) + len(five_ten_thou) + len(six_ten_thou) + len(fin_ten_thou)\n",
    "original_size = first_ten_thou.size + sec_ten_thou.size + thir_ten_thou.size + four_ten_thou.size + five_ten_thou.size + six_ten_thou.size + fin_ten_thou.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing all non-movie titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_ten_thou = first_ten_thou[(first_ten_thou['titleType'].str.contains('movie', case = False)) | (first_ten_thou['titleType'].str.contains('hort', case = False))]\n",
    "sec_ten_thou = sec_ten_thou[(sec_ten_thou['titleType'].str.contains('movie', case = False)) | (sec_ten_thou['titleType'].str.contains('hort', case = False))]\n",
    "thir_ten_thou = thir_ten_thou[((thir_ten_thou['titleType'].str.contains('movie', case = False))  | (thir_ten_thou['titleType'].str.contains('hort', case = False)))]\n",
    "four_ten_thou = four_ten_thou[(four_ten_thou['titleType'].str.contains('movie', case = False)) | (four_ten_thou['titleType'].str.contains('hort', case = False))]\n",
    "five_ten_thou = five_ten_thou[(five_ten_thou['titleType'].str.contains('movie', case = False)) | (five_ten_thou['titleType'].str.contains('hort', case = False))]\n",
    "six_ten_thou = six_ten_thou[(six_ten_thou['titleType'].str.contains('movie', case = False)) | (six_ten_thou['titleType'].str.contains('hort', case = False))]\n",
    "fin_ten_thou = fin_ten_thou[(fin_ten_thou['titleType'].str.contains('movie', case = False)) | (fin_ten_thou['titleType'].str.contains('hort', case = False))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remerging original dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_titles = pd.concat([\n",
    "    first_ten_thou,\n",
    "    sec_ten_thou,\n",
    "    thir_ten_thou,\n",
    "    four_ten_thou,\n",
    "    five_ten_thou,\n",
    "    six_ten_thou,\n",
    "    fin_ten_thou\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping endYear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "del movie_titles['endYear']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replacing \\N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_titles = movie_titles.copy()\n",
    "movie_titles['startYear'] = pd.to_numeric(movie_titles['startYear'], errors = 'coerce')\n",
    "movie_titles['runtimeMinutes'] = pd.to_numeric(movie_titles['runtimeMinutes'], errors = 'coerce')\n",
    "movie_titles = movie_titles.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9998\n",
      "132704\n"
     ]
    }
   ],
   "source": [
    "print(len(movie_titles[movie_titles['isAdult'] == 1]))\n",
    "print(len(movie_titles[movie_titles['titleType'].str.contains('tv', case = False)]))\n",
    "# movie_titles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exporting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_titles.to_csv(str(rel_path) + r'\\..\\src\\movie_titles.csv')\n",
    "new_tuples = len(movie_titles)\n",
    "new_size = movie_titles.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Tuple Count:\t6561312\n",
      "Cleansed Tuple Count:\t1401809\n",
      "Tuples Reduced By: \t78.64%\n",
      "Size Reduced By: \t81.01%\n",
      "Size Reduction: \t93.55%\n",
      "Size Reduction: \t83.5%\n",
      "Size Reduction: \t94.56%\n"
     ]
    }
   ],
   "source": [
    "print(\"Original Tuple Count:\\t\"+str(original_tuples))\n",
    "print(\"Cleansed Tuple Count:\\t\"+ str(new_tuples))\n",
    "percent_tuple_reduction = (100 - round((100 * new_tuples) / original_tuples, 2))\n",
    "print(\"Tuples Reduced By: \\t\"+ str(percent_tuple_reduction)+ \"%\")\n",
    "percent_size_reduction = (100 - round((100 * new_size) / original_size, 2))\n",
    "print('Size Reduced By: \\t' + str(percent_size_reduction) + \"%\")\n",
    "\n",
    "movies_only = movie_titles[movie_titles['titleType'] == 'movie']\n",
    "del movies_only['titleType']\n",
    "\n",
    "no_porn = movie_titles[movie_titles['isAdult'] == 0]\n",
    "del no_porn['isAdult']\n",
    "\n",
    "both = movies_only[movies_only['isAdult'] == 0]\n",
    "del both['isAdult']\n",
    "print('Size Reduction: \\t' + str(100 - round((100 * movies_only.size) / original_size, 2))+\"%\")\n",
    "print('Size Reduction: \\t' + str(100 - round((100 * no_porn.size) / original_size, 2))+\"%\")\n",
    "print('Size Reduction: \\t' + str(100 - round((100 * both.size) / original_size, 2))+\"%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
